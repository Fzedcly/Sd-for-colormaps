# -*- coding: utf-8 -*-
"""
ç”Ÿæˆå·¦â†’å³â€œé»„(#FFFF00) åˆ° çº¢(#FF0000)â€çš„é²œè‰³ã€æ¸…æ™°é¢œè‰²è¡¨ï¼ˆè‰²å¸¦ï¼‰
- å¼ºåˆ¶ Img2Img + ç°åº¦ rampï¼ˆé”å®šä¸º 1D æ¸å˜ï¼‰
- é‡‡æ ·å™¨ï¼šEuler Ancestralï¼ˆå¯¹çº¯è‰²å¸¦æ›´ç¨³ï¼‰
- å…³é—­ Diffusers éšå½¢æ°´å°ï¼ˆé¿å…è“ç‚¹ï¼‰
- LoRA åŠ è½½å¸¦å¼ºæ ¡éªŒï¼ˆå¸¸è§æƒé‡å + fallbackï¼‰
- å¯¼å‡ºä¸‰ä»½ï¼šåŸå°ºå¯¸(256x16)ã€æ ‡å‡†(256x16)ã€è¶…ç»†(256x1)

åœ¨ PyCharmï¼š
- Script pathï¼šæœ¬æ–‡ä»¶
- Working directoryï¼šé¡¹ç›®æ ¹æˆ–æœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•
"""

import os
import numpy as np
from PIL import Image
import torch

from diffusers import (
    StableDiffusionImg2ImgPipeline,
    EulerAncestralDiscreteScheduler,
)

print("[RUNNING FILE]", __file__)  # ç¡®è®¤è·‘çš„æ˜¯è¿™ä»½æ–‡ä»¶

# ========= è·¯å¾„ä¸å°ºå¯¸ =========
MODEL_ID   = "runwayml/stable-diffusion-v1-5"

# â˜…â˜… æ”¹æˆä½ çš„ LoRA ç»å¯¹è·¯å¾„ï¼ˆå»ºè®®ç›®å½•é‡ŒåŒ…å« pytorch_lora_weights.safetensorsï¼‰
LORA_DIR   = r"D:\Studying\Ms.zeng\SD\pythonProject\lora_colormap_output"

# â˜…â˜… æ”¹æˆä½ çš„è¾“å‡ºç›®å½•ç»å¯¹è·¯å¾„
OUTPUT_DIR = r"D:\Studying\Ms.zeng\SD\pythonProject\inference_outputs"

# ç›®æ ‡æ¨ªæ¡å°ºå¯¸ï¼ˆä¸éœ€æ±‚ä¸€è‡´ï¼‰
WIDTH, HEIGHT = 256, 16
VERTICAL = False  # ç«–æ¡è¯·å¯¹è°ƒå®½é«˜å¹¶è®¾ä¸º True

# ========= é‡‡æ ·ä¸æ§åˆ¶ï¼ˆæ›´ç¨³ï¼‰ =========
STEPS    = 30
GUIDANCE = 4.2          # ä½ CFGï¼Œå‡å¼±è¯­ä¹‰å¹»è§‰
STRENGTH = 0.18         # ä½å»å™ªå¼ºåº¦ï¼Œå¼ºä¿ç•™ ramp å½¢çŠ¶ï¼›è‹¥ä¸Šè‰²å¼±å¯ä¸´æ—¶å‡è‡³ 0.35~0.50
SEED     = 123

# LoRA å½±å“åŠ›ï¼ˆé¢œè‰²æ›´â€œè‰³â€ï¼‰
LORA_WEIGHT = 1.6

DTYPE  = torch.float16 if torch.cuda.is_available() else torch.float32
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ========= æç¤ºè¯ï¼ˆé»„â†’çº¢ã€é²œè‰³ã€æ¸…æ™°ï¼‰ =========
PROMPT = (
    "scientific colorbar, pure 1D horizontal color gradient, "
    "left to right: yellow (#FFFF00) to red (#FF0000), "
    "smooth, banding-free, uniform, high saturation, vivid, "
    "no texture, no pattern, no noise, no frame, no ticks"
)

NEGATIVE = (
    "photo, photographic, people, object, scene, background, "
    "world map, earth, continent, ocean, terrain, relief, topography, satellite, "
    "texture, pattern, grain, noise, artifacts, vertical stripes, streaks, bars, columns, "
    "grid, border, frame, labels, numbers, text, watermark, banding, posterization, blur"
)

# ========= å·¥å…·å‡½æ•° =========
def make_ramp(w: int, h: int, vertical: bool = False):
    """ç”Ÿæˆç°åº¦ rampï¼ˆLï¼‰ï¼Œå¤åˆ¶åˆ° RGB é€šé“ä½œä¸º Img2Img æ¡ä»¶å›¾ï¼›åŒæ—¶è¿”å› L ä¾¿äºè‡ªæ£€ä¿å­˜ã€‚"""
    if vertical:
        arr = np.tile(np.linspace(0, 255, h, dtype=np.uint8)[:, None], (1, w))
    else:
        arr = np.tile(np.linspace(0, 255, w, dtype=np.uint8)[None, :], (h, 1))
    imgL = Image.fromarray(arr).convert("L")               # é¿å… Pillow å…³äº mode çš„å¼ƒç”¨è­¦å‘Š
    imgRGB = Image.merge("RGB", (imgL, imgL, imgL))
    return imgRGB, imgL

def seed_everything(seed: int):
    if seed is None or seed < 0:
        seed = torch.randint(0, 2**31-1, (1,)).item()
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)
    np.random.seed(seed % (2**32 - 1))
    return seed

def try_load_lora(pipe, lora_dir: str, lora_scale: float = 1.2) -> bool:
    """å¸¸è§æƒé‡åå°è¯• + ç›®å½•å¼ + fallback attn_procsï¼›è¿”å›æ˜¯å¦åŠ è½½æˆåŠŸã€‚"""
    loaded = False
    names = [
        "pytorch_lora_weights.safetensors",
        "pytorch_lora_weights.bin",
        "diffusers_lora.safetensors",
        "diffusers_lora.bin",
    ]
    for n in names:
        p = os.path.join(lora_dir, n)
        if os.path.exists(p):
            try:
                pipe.load_lora_weights(lora_dir, weight_name=n)
                pipe.fuse_lora(lora_scale=lora_scale)
                print(f"[INFO] LoRA loaded weight={n}, scale={lora_scale}")
                loaded = True
                break
            except Exception as e:
                print(f"[WARN] load {n} failed:", e)

    if not loaded:
        try:
            pipe.load_lora_weights(lora_dir, weight_name=None)
            pipe.fuse_lora(lora_scale=lora_scale)
            print(f"[INFO] LoRA loaded from dir, scale={lora_scale}")
            loaded = True
        except Exception as e:
            print("[WARN] load_lora_weights(dir) failed:", e)

    if not loaded:
        try:
            pipe.unet.load_attn_procs(lora_dir)
            if hasattr(pipe, "text_encoder") and hasattr(pipe.text_encoder, "load_attn_procs"):
                try:
                    pipe.text_encoder.load_attn_procs(lora_dir)
                except Exception:
                    pass
            print(f"[INFO] Fallback attn_procs loaded, scale={lora_scale}")
            loaded = True
        except Exception as e:
            print("[ERR] fallback attn_procs failed:", e)

    print("[INFO] LoRA loaded flag ->", loaded)
    return loaded

def save_resized_variants(img: Image.Image, out_dir: str):
    """å¯¼å‡ºæ ‡å‡†(256x16, LANCZOS) ä¸è¶…ç»†(256x1, BOX) ä¸¤ä»½æˆå“ã€‚"""
    os.makedirs(out_dir, exist_ok=True)
    p1 = os.path.join(out_dir, "colormap_256x16.png")
    p2 = os.path.join(out_dir, "colormap_256x1.png")
    img.resize((256, 16), Image.LANCZOS).save(p1, compress_level=0)
    img.resize((256, 1),  Image.BOX).save(p2, compress_level=0)
    print("Saved:", p1)
    print("Saved:", p2)

# ========= ä¸»æµç¨‹ =========
def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
        MODEL_ID, torch_dtype=DTYPE, safety_checker=None
    )
    # é‡‡æ ·å™¨ï¼šEuler Ancestralï¼ˆæ›´æœä»â€œçº¯æ¸å˜â€çš„çº¦æŸï¼‰
    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)
    pipe = pipe.to(DEVICE)

    # å…³é—­éšå½¢æ°´å°ï¼ˆé˜²è“ç‚¹ï¼‰
    if hasattr(pipe, "watermark"):
        pipe.watermark = None
    if hasattr(pipe, "set_watermark"):
        try:
            pipe.set_watermark(None)
        except Exception:
            pass

    ok = try_load_lora(pipe, LORA_DIR, lora_scale=LORA_WEIGHT)
    assert ok, "âŒ LoRA æœªæˆåŠŸåŠ è½½ï¼šè¯·æ£€æŸ¥ LORA_DIR è·¯å¾„/æ–‡ä»¶åï¼ˆå»ºè®®ä½¿ç”¨ç»å¯¹è·¯å¾„ä¸ pytorch_lora_weights.safetensorsï¼‰"

    # ç”Ÿæˆ ramp å¹¶ä¿å­˜è°ƒè¯•å›¾
    init_rgb, init_L = make_ramp(WIDTH, HEIGHT, vertical=VERTICAL)
    init_L_path = os.path.join(OUTPUT_DIR, "_debug_ramp.png")
    init_L.save(init_L_path, compress_level=0)
    print("[INFO] init ramp size =", init_rgb.size, "| saved:", init_L_path)

    seed = seed_everything(SEED)
    print("[INFO] Seed =", seed)
    gen = torch.Generator(device=DEVICE).manual_seed(seed)

    out = pipe(
        prompt=PROMPT,
        negative_prompt=NEGATIVE,
        image=init_rgb,
        strength=STRENGTH,
        guidance_scale=GUIDANCE,
        num_inference_steps=STEPS,
        generator=gen,
    ).images[0]

    print("[INFO] output size =", out.size)
    assert out.size == init_rgb.size, "âŒ è¾“å‡ºå°ºå¯¸ != ramp å°ºå¯¸ï¼ˆRun é…ç½®æˆ–æµç¨‹æœ‰è¯¯ï¼‰"

    base = f"colormap_seed{seed}_{WIDTH}x{HEIGHT}.png"
    p0 = os.path.join(OUTPUT_DIR, base)
    out.save(p0, compress_level=0)
    print("Saved:", p0)

    # å¯¼å‡ºæ ‡å‡†ä¸è¶…ç»†ä¸¤ä»½
    save_resized_variants(out, OUTPUT_DIR)
    print("ğŸ‰ å®Œæˆï¼")

if __name__ == "__main__":
    main()
